{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No need to run if csv files are downloaded already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amazon Transactions\n",
    "data = [\n",
    "    {\"Transaction ID\": \"Trans1\", \"Books\": \"A Beginner’s Guide, Java: The Complete Reference, Java For Dummies, Android Programming: The Big Nerd Ranch\"},\n",
    "    {\"Transaction ID\": \"Trans2\", \"Books\": \"A Beginner’s Guide, Java: The Complete Reference, Java For Dummies\"},\n",
    "    {\"Transaction ID\": \"Trans3\", \"Books\": \"A Beginner’s Guide, Java: The Complete Reference, Java For Dummies, Android Programming: The Big Nerd Ranch, Head First Java 2nd Edition\"},\n",
    "    {\"Transaction ID\": \"Trans4\", \"Books\": \"Android Programming: The Big Nerd Ranch, Head First Java 2nd Edition, Beginning Programming with Java\"},\n",
    "    {\"Transaction ID\": \"Trans5\", \"Books\": \"Android Programming: The Big Nerd Ranch, Beginning Programming with Java, Java 8 Pocket Guide\"},\n",
    "    {\"Transaction ID\": \"Trans6\", \"Books\": \"A Beginner’s Guide, Android Programming: The Big Nerd Ranch, Head First Java 2nd Edition\"},\n",
    "    {\"Transaction ID\": \"Trans7\", \"Books\": \"A Beginner’s Guide, Head First Java 2nd Edition, Beginning Programming with Java\"},\n",
    "    {\"Transaction ID\": \"Trans8\", \"Books\": \"Java: The Complete Reference, Java For Dummies, Android Programming: The Big Nerd Ranch\"},\n",
    "    {\"Transaction ID\": \"Trans9\", \"Books\": \"Java For Dummies, Android Programming: The Big Nerd Ranch, Head First Java 2nd Edition, Beginning Programming with Java\"},\n",
    "    {\"Transaction ID\": \"Trans10\", \"Books\": \"Beginning Programming with Java, Java 8 Pocket Guide, C++ Programming in Easy Steps\"},\n",
    "    {\"Transaction ID\": \"Trans11\", \"Books\": \"A Beginner’s Guide, Java: The Complete Reference, Java For Dummies, Android Programming: The Big Nerd Ranch\"},\n",
    "    {\"Transaction ID\": \"Trans12\", \"Books\": \"A Beginner’s Guide, Java: The Complete Reference, Java For Dummies, HTML and CSS: Design and Build Websites\"},\n",
    "    {\"Transaction ID\": \"Trans13\", \"Books\": \"A Beginner’s Guide, Java: The Complete Reference, Java For Dummies, Java 8 Pocket Guide, HTML and CSS: Design and Build Websites\"},\n",
    "    {\"Transaction ID\": \"Trans14\", \"Books\": \"Java For Dummies, Android Programming: The Big Nerd Ranch, Head First Java 2nd Edition\"},\n",
    "    {\"Transaction ID\": \"Trans15\", \"Books\": \"Java For Dummies, Android Programming: The Big Nerd Ranch\"},\n",
    "    {\"Transaction ID\": \"Trans16\", \"Books\": \"A Beginner’s Guide, Java: The Complete Reference, Java For Dummies, Android Programming: The Big Nerd Ranch\"},\n",
    "    {\"Transaction ID\": \"Trans17\", \"Books\": \"A Beginner’s Guide, Java: The Complete Reference, Java For Dummies, Android Programming: The Big Nerd Ranch\"},\n",
    "    {\"Transaction ID\": \"Trans18\", \"Books\": \"Head First Java 2nd Edition, Beginning Programming with Java, Java 8 Pocket Guide\"},\n",
    "    {\"Transaction ID\": \"Trans19\", \"Books\": \"Android Programming: The Big Nerd Ranch, Head First Java 2nd Edition\"},\n",
    "    {\"Transaction ID\": \"Trans20\", \"Books\": \"A Beginner’s Guide, Java: The Complete Reference, Java For Dummies\"}\n",
    "]\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file = \"amazon.csv\"\n",
    "\n",
    "# Write the data to the CSV file\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    fieldnames = ['Transaction ID', 'Books']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for row in data:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"CSV file '{csv_file}' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BestBuy Transactions\n",
    "data1 = [\n",
    "    {\"Transaction ID\": \"Trans1\", \"Items\": \"Desk Top, Printer, Flash Drive, Microsoft Office, Speakers, Anti-Virus\"},\n",
    "    {\"Transaction ID\": \"Trans2\", \"Items\": \"Lab Top, Flash Drive, Microsoft Office, Lab Top Case, Anti-Virus\"},\n",
    "    {\"Transaction ID\": \"Trans3\", \"Items\": \"Lab Top, Printer, Flash Drive, Microsoft Office, Anti-Virus, Lab Top Case, External Hard-Drive\"},\n",
    "    {\"Transaction ID\": \"Trans4\", \"Items\": \"Lab Top, Printer, Flash Drive, Anti-Virus, External Hard-Drive, Lab Top Case\"},\n",
    "    {\"Transaction ID\": \"Trans5\", \"Items\": \"Lab Top, Flash Drive, Lab Top Case, Anti-Virus\"},\n",
    "    {\"Transaction ID\": \"Trans6\", \"Items\": \"Lab Top, Printer, Flash Drive, Microsoft Office\"},\n",
    "    {\"Transaction ID\": \"Trans7\", \"Items\": \"Desk Top, Printer, Flash Drive, Microsoft Office\"},\n",
    "    {\"Transaction ID\": \"Trans8\", \"Items\": \"Lab Top, External Hard-Drive, Anti-Virus\"},\n",
    "    {\"Transaction ID\": \"Trans9\", \"Items\": \"Desk Top, Printer, Flash Drive, Microsoft Office, Lab Top Case, Anti-Virus, Speakers, External Hard-Drive\"},\n",
    "    {\"Transaction ID\": \"Trans10\", \"Items\": \"Digital Camera, Lab Top, Desk Top, Printer, Flash Drive, Microsoft Office, Lab Top Case, Anti-Virus, External Hard-Drive, Speakers\"},\n",
    "    {\"Transaction ID\": \"Trans11\", \"Items\": \"Lab Top, Desk Top, Lab Top Case, External Hard-Drive, Speakers, Anti-Virus\"},\n",
    "    {\"Transaction ID\": \"Trans12\", \"Items\": \"Digital Camera, Lab Top, Lab Top Case, External Hard-Drive, Anti-Virus, Speakers\"},\n",
    "    {\"Transaction ID\": \"Trans13\", \"Items\": \"Digital Camera, Speakers\"},\n",
    "    {\"Transaction ID\": \"Trans14\", \"Items\": \"Digital Camera, Desk Top, Printer, Flash Drive, Microsoft Office\"},\n",
    "    {\"Transaction ID\": \"Trans15\", \"Items\": \"Printer, Flash Drive, Microsoft Office, Anti-Virus, Lab Top Case, Speakers, External Hard-Drive\"},\n",
    "    {\"Transaction ID\": \"Trans16\", \"Items\": \"Digital Camera, Flash Drive, Microsoft Office, Anti-Virus, Lab Top Case, External Hard-Drive, Speakers\"},\n",
    "    {\"Transaction ID\": \"Trans17\", \"Items\": \"Digital Camera, Lab Top, Lab Top Case\"},\n",
    "    {\"Transaction ID\": \"Trans18\", \"Items\": \"Digital Camera, Lab Top Case, Speakers\"},\n",
    "    {\"Transaction ID\": \"Trans19\", \"Items\": \"Digital Camera, Lab Top, Printer, Flash Drive, Microsoft Office, Speakers, Lab Top Case, Anti-Virus\"},\n",
    "    {\"Transaction ID\": \"Trans20\", \"Items\": \"Digital Camera, Lab Top, Speakers, Anti-Virus, Lab Top Case\"}\n",
    "]\n",
    "\n",
    "# Define the CSV file path for Transaction Type 1\n",
    "csv_file1 = \"BestBuy.csv\"\n",
    "\n",
    "# Write the data to the CSV file for Transaction Type 1\n",
    "with open(csv_file1, mode='w', newline='') as file1:\n",
    "    fieldnames1 = ['Transaction ID', 'Items']\n",
    "    writer1 = csv.DictWriter(file1, fieldnames=fieldnames1)\n",
    "\n",
    "    writer1.writeheader()\n",
    "    for row1 in data1:\n",
    "        writer1.writerow(row1)\n",
    "\n",
    "print(f\"CSV file '{csv_file1}' for BestBuy Transactions has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kmart Transactions\n",
    "\n",
    "data2 = [\n",
    "    {\"Transaction ID\": \"Trans1\", \"Items\": \"Decorative Pillows, Quilts, Embroidered Bedspread\"},\n",
    "    {\"Transaction ID\": \"Trans2\", \"Items\": \"Embroidered Bedspread, Shams, Kids Bedding, Bedding Collections, Bed Skirts, Bedspreads, Sheets\"},\n",
    "    {\"Transaction ID\": \"Trans3\", \"Items\": \"Decorative Pillows, Quilts, Embroidered Bedspread, Shams, Kids Bedding, Bedding Collections\"},\n",
    "    {\"Transaction ID\": \"Trans4\", \"Items\": \"Kids Bedding, Bedding Collections, Sheets, Bedspreads, Bed Skirts\"},\n",
    "    {\"Transaction ID\": \"Trans5\", \"Items\": \"Decorative Pillows, Kids Bedding, Bedding Collections, Sheets, Bed Skirts, Bedspreads\"},\n",
    "    {\"Transaction ID\": \"Trans6\", \"Items\": \"Bedding Collections, Bedspreads, Bed Skirts, Sheets, Shams, Kids Bedding\"},\n",
    "    {\"Transaction ID\": \"Trans7\", \"Items\": \"Decorative Pillows, Quilts\"},\n",
    "    {\"Transaction ID\": \"Trans8\", \"Items\": \"Decorative Pillows, Quilts, Embroidered Bedspread\"},\n",
    "    {\"Transaction ID\": \"Trans9\", \"Items\": \"Bedspreads, Bed Skirts, Shams, Kids Bedding, Sheets\"},\n",
    "    {\"Transaction ID\": \"Trans10\", \"Items\": \"Quilts, Embroidered Bedspread, Bedding Collections\"},\n",
    "    {\"Transaction ID\": \"Trans11\", \"Items\": \"Bedding Collections, Bedspreads, Bed Skirts, Kids Bedding, Shams, Sheets\"},\n",
    "    {\"Transaction ID\": \"Trans12\", \"Items\": \"Decorative Pillows, Quilts\"},\n",
    "    {\"Transaction ID\": \"Trans13\", \"Items\": \"Embroidered Bedspread, Shams\"},\n",
    "    {\"Transaction ID\": \"Trans14\", \"Items\": \"Sheets, Shams, Bed Skirts, Kids Bedding\"},\n",
    "    {\"Transaction ID\": \"Trans15\", \"Items\": \"Decorative Pillows, Quilts\"},\n",
    "    {\"Transaction ID\": \"Trans16\", \"Items\": \"Decorative Pillows, Kids Bedding, Bed Skirts, Shams\"},\n",
    "    {\"Transaction ID\": \"Trans17\", \"Items\": \"Decorative Pillows, Shams, Bed Skirts\"},\n",
    "    {\"Transaction ID\": \"Trans18\", \"Items\": \"Quilts, Sheets, Kids Bedding\"},\n",
    "    {\"Transaction ID\": \"Trans19\", \"Items\": \"Shams, Bed Skirts, Kids Bedding, Sheets\"},\n",
    "    {\"Transaction ID\": \"Trans20\", \"Items\": \"Decorative Pillows, Bedspreads, Shams, Sheets, Bed Skirts, Kids Bedding\"}\n",
    "]\n",
    "\n",
    "# Define the CSV file path for Transaction Type 2\n",
    "csv_file2 = \"Kmart.csv\"\n",
    "\n",
    "# Write the data to the CSV file for Transaction Type 2\n",
    "with open(csv_file2, mode='w', newline='') as file2:\n",
    "    fieldnames2 = ['Transaction ID', 'Items']\n",
    "    writer2 = csv.DictWriter(file2, fieldnames=fieldnames2)\n",
    "\n",
    "    writer2.writeheader()\n",
    "    for row2 in data2:\n",
    "        writer2.writerow(row2)\n",
    "\n",
    "print(f\"CSV file '{csv_file2}' for Kmart Transactions has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nike transactions\n",
    "\n",
    "data3 = [\n",
    "    {\"Transaction ID\": \"Trans1\", \"Items\": \"Running Shoe, Socks, Sweatshirts, Modern Pants\"},\n",
    "    {\"Transaction ID\": \"Trans2\", \"Items\": \"Running Shoe, Socks, Sweatshirts\"},\n",
    "    {\"Transaction ID\": \"Trans3\", \"Items\": \"Running Shoe, Socks, Sweatshirts, Modern Pants\"},\n",
    "    {\"Transaction ID\": \"Trans4\", \"Items\": \"Running Shoe, Sweatshirts, Modern Pants\"},\n",
    "    {\"Transaction ID\": \"Trans5\", \"Items\": \"Running Shoe, Socks, Sweatshirts, Modern Pants, Soccer Shoe\"},\n",
    "    {\"Transaction ID\": \"Trans6\", \"Items\": \"Running Shoe, Socks, Sweatshirts\"},\n",
    "    {\"Transaction ID\": \"Trans7\", \"Items\": \"Running Shoe, Socks, Sweatshirts, Modern Pants, Tech Pants, Rash Guard, Hoodies\"},\n",
    "    {\"Transaction ID\": \"Trans8\", \"Items\": \"Swimming Shirt, Socks, Sweatshirts\"},\n",
    "    {\"Transaction ID\": \"Trans9\", \"Items\": \"Swimming Shirt, Rash Guard, Dry Fit V-Nick, Hoodies, Tech Pants\"},\n",
    "    {\"Transaction ID\": \"Trans10\", \"Items\": \"Swimming Shirt, Rash Guard, Dry\"},\n",
    "    {\"Transaction ID\": \"Trans11\", \"Items\": \"Swimming Shirt, Rash Guard, Dry Fit V-Nick\"},\n",
    "    {\"Transaction ID\": \"Trans12\", \"Items\": \"Running Shoe, Swimming Shirt, Socks, Sweatshirts, Modern Pants, Soccer Shoe, Rash Guard, Hoodies, Tech Pants, Dry Fit V-Nick\"},\n",
    "    {\"Transaction ID\": \"Trans13\", \"Items\": \"Running Shoe, Swimming Shirt, Socks, Sweatshirts, Modern Pants, Soccer Shoe, Rash Guard, Tech Pants, Dry Fit V-Nick, Hoodies\"},\n",
    "    {\"Transaction ID\": \"Trans14\", \"Items\": \"Running Shoe, Swimming Shirt, Rash Guard, Tech Pants, Hoodies, Dry Fit V-Nick\"},\n",
    "    {\"Transaction ID\": \"Trans15\", \"Items\": \"Running Shoe, Swimming Shirt, Socks, Sweatshirts, Modern Pants, Dry Fit V-Nick, Rash Guard, Tech Pants\"},\n",
    "    {\"Transaction ID\": \"Trans16\", \"Items\": \"Swimming Shirt, Soccer Shoe, Hoodies, Dry Fit V-Nick, Tech Pants, Rash Guard\"},\n",
    "    {\"Transaction ID\": \"Trans17\", \"Items\": \"Running Shoe, Socks\"},\n",
    "    {\"Transaction ID\": \"Trans18\", \"Items\": \"Socks, Sweatshirts, Modern Pants, Soccer Shoe, Hoodies, Rash Guard, Tech Pants, Dry Fit V-Nick\"},\n",
    "    {\"Transaction ID\": \"Trans19\", \"Items\": \"Running Shoe, Swimming Shirt, Rash Guard\"},\n",
    "    {\"Transaction ID\": \"Trans20\", \"Items\": \"Running Shoe, Swimming Shirt, Socks, Sweatshirts, Modern Pants, Soccer Shoe, Hoodies, Tech Pants, Rash Guard, Dry Fit V-Nick\"}\n",
    "]\n",
    "\n",
    "# Define the CSV file path for Transaction Type 3\n",
    "csv_file3 = \"nike.csv\"\n",
    "\n",
    "# Write the data to the CSV file for Transaction Type 3\n",
    "with open(csv_file3, mode='w', newline='') as file3:\n",
    "    fieldnames3 = ['Transaction ID', 'Items']\n",
    "    writer3 = csv.DictWriter(file3, fieldnames=fieldnames3)\n",
    "\n",
    "    writer3.writeheader()\n",
    "    for row3 in data3:\n",
    "        writer3.writerow(row3)\n",
    "\n",
    "print(f\"CSV file '{csv_file3}' for nike Transaction has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Transactions\n",
    "data4 = [\n",
    "    {\"Transaction ID\": \"Trans1\", \"Items\": \"A, B, C\"},\n",
    "    {\"Transaction ID\": \"Trans2\", \"Items\": \"A, B, C\"},\n",
    "    {\"Transaction ID\": \"Trans3\", \"Items\": \"A, B, C, D\"},\n",
    "    {\"Transaction ID\": \"Trans4\", \"Items\": \"A, B, C, D, E\"},\n",
    "    {\"Transaction ID\": \"Trans5\", \"Items\": \"A, B, D, E\"},\n",
    "    {\"Transaction ID\": \"Trans6\", \"Items\": \"A, D, E\"},\n",
    "    {\"Transaction ID\": \"Trans7\", \"Items\": \"A, E\"},\n",
    "    {\"Transaction ID\": \"Trans8\", \"Items\": \"A, E\"},\n",
    "    {\"Transaction ID\": \"Trans9\", \"Items\": \"A, C, E\"},\n",
    "    {\"Transaction ID\": \"Trans10\", \"Items\": \"A, C, E\"},\n",
    "    {\"Transaction ID\": \"Trans11\", \"Items\": \"A, C, E\"}\n",
    "]\n",
    "\n",
    "# Define the CSV file path for Transaction Type 4\n",
    "csv_file4 = \"Generic.csv\"\n",
    "\n",
    "# Write the data to the CSV file for Transaction Type 4\n",
    "with open(csv_file4, mode='w', newline='') as file4:\n",
    "    fieldnames4 = ['Transaction ID', 'Items']\n",
    "    writer4 = csv.DictWriter(file4, fieldnames=fieldnames4)\n",
    "\n",
    "    writer4.writeheader()\n",
    "    for row4 in data4:\n",
    "        writer4.writerow(row4)\n",
    "\n",
    "print(f\"CSV file '{csv_file4}' for Generic Transaction has been created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a dataset (1-5): \n",
      "1.Amazon\n",
      "2.BestBuy\n",
      "3.Kmart\n",
      "4.Nike\n",
      "5.Generic\n",
      "5\n",
      "Enter minimum support (as a decimal): 0.5\n",
      "Enter minimum confidence (as a decimal): 0.5\n",
      "\n",
      "Brute Force Execution Time: 0.0003609657287597656 seconds\n",
      "Brute Force Association Rules:\n",
      "A -> C, Confidence: 0.64\n",
      "C -> A, Confidence: 1.00\n",
      "A -> E, Confidence: 0.73\n",
      "E -> A, Confidence: 1.00\n",
      "\n",
      "\n",
      "Apriori Execution Time: 0.01024007797241211 seconds\n",
      "C -> A, Confidence: 1.00\n",
      "A -> C, Confidence: 0.64\n",
      "A -> E, Confidence: 0.73\n",
      "E -> A, Confidence: 1.00\n",
      "\n",
      "\n",
      "FP-Growth Execution Time: 0.005077362060546875 seconds\n",
      "C -> A, Confidence: 1.00\n",
      "A -> C, Confidence: 0.64\n",
      "A -> E, Confidence: 0.73\n",
      "E -> A, Confidence: 1.00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import time\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "import pandas as pd\n",
    "\n",
    "#Brute Force\n",
    "def brute_force(transactions, min_support, min_confidence):\n",
    "    items = set(item for transaction in transactions for item in transaction)\n",
    "    itemsets = []\n",
    "    for i in range(1, len(items) + 1):\n",
    "        itemsets.extend(itertools.combinations(items, i))\n",
    "    frequent_itemsets = {}\n",
    "    for itemset in itemsets:\n",
    "        frequency = sum(1 for transaction in transactions if set(itemset).issubset(transaction))\n",
    "        if frequency / len(transactions) >= min_support:\n",
    "            frequent_itemsets[itemset] = frequency\n",
    "    return generate_association_rules(frequent_itemsets, transactions, min_confidence)\n",
    "\n",
    "def generate_association_rules(frequent_itemsets, transactions, min_confidence):\n",
    "    rules = []\n",
    "    for itemset, frequency in frequent_itemsets.items():\n",
    "        for i in range(1, len(itemset)):\n",
    "            for antecedent in itertools.combinations(itemset, i):\n",
    "                consequent = set(itemset) - set(antecedent)\n",
    "                antecedent_transactions = sum(1 for transaction in transactions if set(antecedent).issubset(transaction))\n",
    "                if antecedent_transactions > 0:\n",
    "                    confidence = frequency / antecedent_transactions\n",
    "                    if confidence >= min_confidence:\n",
    "                        rules.append((antecedent, consequent, confidence))\n",
    "    return rules\n",
    "\n",
    "def read_data(filename):\n",
    "    transactions = []\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)  # Skip header row\n",
    "        for row in csv_reader:\n",
    "            transactions.append(row[1].split(\", \"))\n",
    "    return transactions\n",
    "\n",
    "def print_rules(rules, method):\n",
    "    print(f\"{method} Association Rules:\")\n",
    "    for rule in rules:\n",
    "        antecedents = ', '.join(rule[0])\n",
    "        consequents = ', '.join(rule[1])\n",
    "        print(f\"{antecedents} -> {consequents}, Confidence: {rule[2]:.2f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "def run_apriori_fpgrowth(transactions, min_support, min_confidence):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    #Apriori\n",
    "    \n",
    "    start_time = time.time()\n",
    "    frequent_itemsets_apriori = apriori(df, min_support=min_support, use_colnames=True)\n",
    "    rules_apriori = association_rules(frequent_itemsets_apriori, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    end_time = time.time()\n",
    "    print(f\"Apriori Execution Time: {end_time - start_time} seconds\")\n",
    "    if not rules_apriori.empty:\n",
    "        for index, row in rules_apriori.iterrows():\n",
    "            print(f\"{' , '.join(row['antecedents'])} -> {' , '.join(row['consequents'])}, Confidence: {row['confidence']:.2f}\")\n",
    "    else:\n",
    "        print(\"No association rules found.\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # FP-Growth\n",
    "    \n",
    "    start_time = time.time()\n",
    "    frequent_itemsets_fp = fpgrowth(df, min_support=min_support, use_colnames=True)\n",
    "    rules_fp = association_rules(frequent_itemsets_fp, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    end_time = time.time()\n",
    "    print(f\"FP-Growth Execution Time: {end_time - start_time} seconds\")\n",
    "    if not rules_fp.empty:\n",
    "        for index, row in rules_fp.iterrows():\n",
    "            print(f\"{' , '.join(row['antecedents'])} -> {' , '.join(row['consequents'])}, Confidence: {row['confidence']:.2f}\")\n",
    "    else:\n",
    "        print(\"No association rules found.\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "def main():\n",
    "    datasets = [\"amazon.csv\", \"BestBuy.csv\", \"Kmart.csv\", \"nike.csv\", \"Generic.csv\"]\n",
    "    dataset_choice = int(input(\"Choose a dataset (1-5): \\n1.Amazon\\n2.BestBuy\\n3.Kmart\\n4.Nike\\n5.Generic\\n\"))\n",
    "    min_support = float(input(\"Enter minimum support (as a decimal): \"))\n",
    "    min_confidence = float(input(\"Enter minimum confidence (as a decimal): \"))\n",
    "\n",
    "    transactions = read_data(datasets[dataset_choice - 1])\n",
    "\n",
    "    # Brute Force\n",
    "    start_time = time.time()\n",
    "    rules_brute_force = brute_force(transactions, min_support, min_confidence)\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nBrute Force Execution Time: {end_time - start_time} seconds\")\n",
    "    print_rules(rules_brute_force, \"Brute Force\")\n",
    "\n",
    "    # Apriori and FP-Growth\n",
    "    run_apriori_fpgrowth(transactions, min_support, min_confidence)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
